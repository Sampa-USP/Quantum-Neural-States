{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18304402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyscf\n",
    "from pyscf import gto, scf, fci\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "518f5ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyscf.gto.mole.Mole at 0x2b056cfb8f10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Distância de ligação C-H experimental (em Å)\n",
    "r_ch = 1.087\n",
    "\n",
    "# Coordenadas tetraédricas (baseadas em r_ch)\n",
    "# A = r_ch / sqrt(3)\n",
    "a = r_ch / np.sqrt(3)\n",
    "\n",
    "mol = gto.M(\n",
    "    atom=[\n",
    "        ['C', ( 0.0,  0.0,  0.0)],\n",
    "        ['H', (  a,    a,    a )],\n",
    "        ['H', (  a,   -a,   -a )],\n",
    "        ['H', ( -a,    a,   -a )],\n",
    "        ['H', ( -a,   -a,    a )]\n",
    "    ],\n",
    "    basis='6-31g(d)',  # Base mínima\n",
    "    spin=0,          # Singlete (10 elétrons)\n",
    "    symmetry=True    # Habilitar simetria (Td)\n",
    ")\n",
    "mol.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888e5a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged SCF energy = -40.1948109553752\n",
      "Energia Hartree-Fock (RHF): -40.19481096 Hartrees\n"
     ]
    }
   ],
   "source": [
    "# 1. Calcular a energia Hartree-Fock\n",
    "myhf = scf.RHF(mol).run()\n",
    "\n",
    "print(f\"Energia Hartree-Fock (RHF): {myhf.e_tot:.8f} Hartrees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0c1c67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<class 'pyscf.fci.FCI.<locals>.CISolver'> does not have attributes  nthreads\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARN: Not enough memory for FCI solver. The minimal requirement is 10403 MB\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] Can't write data (file write failed: time = Thu Oct 23 20:05:02 2025\n, filename = '/tmp/6frno5pq', file descriptor = 58, errno = 28, error message = 'No space left on device', buf = 0x2b088d9e3810, total write size = 746657504, bytes this sub-write = 746657504, bytes actually written = 18446744073709551615, offset = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6576/1292921298.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# myfci.kernel() diagonaliza a matriz Hamiltoniana FCI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Retorna: (energia_fci, vetor_de_onda_fci)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0me_fci_pyscf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcivec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyfci\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Energia Full CI (PySCF):    {e_fci_pyscf:.8f} Hartrees\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.7/site-packages/pyscf/fci/__init__.py\u001b[0m in \u001b[0;36mkernel\u001b[0;34m(self, h1e, eri, norb, nelec, ci0, ecore, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m                    ecore=ecore, **kwargs):\n\u001b[1;32m    225\u001b[0m             return fcisolver_class.kernel(self, h1e, eri, norb, nelec, ci0,\n\u001b[0;32m--> 226\u001b[0;31m                                           ecore=ecore, **kwargs)\n\u001b[0m\u001b[1;32m    227\u001b[0m     \u001b[0mcisolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCISolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mcisolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfcisolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.7/site-packages/pyscf/fci/direct_spin1_symm.py\u001b[0m in \u001b[0;36mkernel\u001b[0;34m(self, h1e, eri, norb, nelec, ci0, tol, lindep, max_cycle, max_space, nroots, davidson_only, pspace_size, orbsym, wfnsym, ecore, **kwargs)\u001b[0m\n\u001b[1;32m    831\u001b[0m             e, c = direct_spin1.kernel_ms1(\n\u001b[1;32m    832\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh1e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnelec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlindep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_cycle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 max_space, nroots, davidson_only, pspace_size, ecore=ecore, **kwargs)\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0mna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlink_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.7/site-packages/pyscf/fci/direct_spin1.py\u001b[0m in \u001b[0;36mkernel_ms1\u001b[0;34m(fci, h1e, eri, norb, nelec, ci0, link_index, tol, lindep, max_cycle, max_space, nroots, davidson_only, pspace_size, hop, max_memory, verbose, ecore, **kwargs)\u001b[0m\n\u001b[1;32m    730\u001b[0m                        \u001b[0mmax_cycle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnroots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnroots\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                        \u001b[0mmax_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                        tol_residual=tol_residual, **kwargs)\n\u001b[0m\u001b[1;32m    733\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mecore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.7/site-packages/pyscf/fci/direct_spin1.py\u001b[0m in \u001b[0;36meig\u001b[0;34m(self, op, x0, precond, **kwargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m                 lib.davidson1(lambda xs: [op(x) for x in xs],\n\u001b[0;32m--> 927\u001b[0;31m                               x0, precond, lessio=self.lessio, **kwargs)\n\u001b[0m\u001b[1;32m    928\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nroots'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.7/site-packages/pyscf/lib/linalg_helper.py\u001b[0m in \u001b[0;36mdavidson1\u001b[0;34m(aop, x0, precond, tol, max_cycle, max_space, lindep, max_memory, dot, callback, nroots, lessio, pick, verbose, follow_state, tol_residual, fill_heff)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m             \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0mrnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrnow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.7/site-packages/pyscf/lib/linalg_helper.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscr_h5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1536\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscr_h5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.7/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, name, obj)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m                 \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m                 \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.7/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    181\u001b[0m                     \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mdsid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_new_dset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0mdset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.7/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mdset_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdset_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.DatasetID.write\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_proxy.pyx\u001b[0m in \u001b[0;36mh5py._proxy.dset_rw\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] Can't write data (file write failed: time = Thu Oct 23 20:05:02 2025\n, filename = '/tmp/6frno5pq', file descriptor = 58, errno = 28, error message = 'No space left on device', buf = 0x2b088d9e3810, total write size = 746657504, bytes this sub-write = 746657504, bytes actually written = 18446744073709551615, offset = 0)"
     ]
    }
   ],
   "source": [
    "# 2. Calcular a energia Full CI\n",
    "# Inicializamos o resolvedor FCI com o objeto 'myhf' (que contém os orbitais)\n",
    "myfci = fci.FCI(myhf)\n",
    "\n",
    "myfci.nthreads = 40\n",
    "\n",
    "# myfci.kernel() diagonaliza a matriz Hamiltoniana FCI\n",
    "# Retorna: (energia_fci, vetor_de_onda_fci)\n",
    "e_fci_pyscf, fcivec = myfci.kernel()\n",
    "\n",
    "print(f\"Energia Full CI (PySCF):    {e_fci_pyscf:.8f} Hartrees\")\n",
    "\n",
    "# A diferença entre FCI e HF é a energia de correlação\n",
    "e_corr = e_fci_pyscf - myhf.e_tot\n",
    "print(f\"Energia de Correlação:      {e_corr:.8f} Hartrees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ce8b05",
   "metadata": {},
   "source": [
    "Valor experimental: \n",
    "\n",
    "Metano,CH₄,-40.526"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8590e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyscf\n",
    "from pyscf import gto, scf, fci, cc\n",
    "import dask\n",
    "from dask_jobqueue import SLURMCluster  # Mude para PBSCluster, SGECluster, etc. se necessário\n",
    "from dask.distributed import Client\n",
    "import time\n",
    "import os\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# PASSO 1: A FUNÇÃO DE CÁLCULO\n",
    "# Esta função será serializada e enviada para o HPC.\n",
    "# Ela deve ser autossuficiente.\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "def run_pyscf_fci(atom_string, basis, spin):\n",
    "    \"\"\"\n",
    "    Executa um cálculo SCF (HF) seguido de Full CI no HPC.\n",
    "    Recebe strings para construir a molécula remotamente.\n",
    "    \"\"\"\n",
    "    # Importações devem estar DENTRO da função\n",
    "    from pyscf import gto, scf, fci\n",
    "    \n",
    "    # 1. Construir a molécula NO WORKER (no HPC)\n",
    "    mol = gto.M(\n",
    "        atom=atom_string,\n",
    "        basis=basis,\n",
    "        spin=spin,\n",
    "        verbose=0 # Importante para não poluir os logs\n",
    "    )\n",
    "    mol.build()\n",
    "    \n",
    "    # 2. Executar Hartree-Fock\n",
    "    myhf = scf.RHF(mol).run()\n",
    "    \n",
    "    # 3. Executar Full CI (A PARTE PESADA)\n",
    "    myfci = fci.FCI(myhf)\n",
    "    e_fci, _ = myfci.kernel()\n",
    "    \n",
    "    return e_fci\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56759a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# PASSO 2: DEFINIR OS CÁLCULOS\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "# Molécula leve (para rodar local)\n",
    "h2_atom = 'H 0 0 0; H 0 0 0.74'\n",
    "h2_basis = 'sto-3g'\n",
    "h2_spin = 0\n",
    "\n",
    "# Molécula PESADA (para rodar no HPC)\n",
    "# N2 @ 6-31G -> 14 elétrons, 14 orbitais\n",
    "# Tamanho do FCI: C(14, 7) * C(14, 7) = 3432 * 3432 = 11.7 milhões de termos\n",
    "# Impraticável em um laptop, fácil para um nó de HPC.\n",
    "ch4_atom =[\n",
    "        ['C', ( 0.0,  0.0,  0.0)],\n",
    "        ['H', (  1.087 / np.sqrt(3),    1.087 / np.sqrt(3),    1.087 / np.sqrt(3) )],\n",
    "        ['H', (  1.087 / np.sqrt(3),   -1.087 / np.sqrt(3),   -1.087 / np.sqrt(3) )],\n",
    "        ['H', ( -1.087 / np.sqrt(3),    1.087 / np.sqrt(3),   -1.087 / np.sqrt(3) )],\n",
    "        ['H', ( -1.087 / np.sqrt(3),   -1.087 / np.sqrt(3),    1.087 / np.sqrt(3) )]\n",
    "    ]\n",
    "ch4_basis = '6-31G'\n",
    "ch4_spin=0,          # Singlete (10 elétrons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7455a6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Cálculo LOCAL (H2) ---\n",
      "Energia Local H2 (FCI/sto-3g): -1.13728383 Ha\n",
      "Tempo local: 0.04 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# PASSO 3: CÁLCULO LOCAL (TRANSPARENTE)\n",
    "# -----------------------------------------------------------------\n",
    "print(\"--- Iniciando Cálculo LOCAL (H2) ---\")\n",
    "start_local = time.time()\n",
    "\n",
    "# Simplesmente chamamos a função normalmente\n",
    "e_local_h2 = run_pyscf_fci(h2_atom, h2_basis, h2_spin)\n",
    "\n",
    "end_local = time.time()\n",
    "print(f\"Energia Local H2 (FCI/{h2_basis}): {e_local_h2:.8f} Ha\")\n",
    "print(f\"Tempo local: {end_local - start_local:.2f} s\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25ecf1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Configurando Conexão com o Cluster HPC ---\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 45] Operation not supported: '/home/nara'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- Configurando Conexão com o Cluster HPC ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# (Baseado na configuração do seu HPC)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m cluster = \u001b[43mSLURMCluster\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcompute\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# Nome da fila/partição do Slurm (ex: 'batch', 'shared')\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfci-ch4\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m# O nome do seu projeto/conta para cobrança\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcores\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m24\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# Quantos cores CADA job (worker) deve pedir\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m100GB\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Quanta RAM CADA job (worker) deve pedir\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwalltime\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m01:00:00\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Tempo máximo do job (HH:MM:SS)\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Configuração de rede (CRUCIAL)\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Tente 'ib0' (InfiniBand) ou 'eth0' (Ethernet)\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Peça ao admin do seu HPC qual interface usar\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterface\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mib0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Onde salvar os logs dos workers no HPC\u001b[39;49;00m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/home/nara/dask-logs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Comandos para carregar seu ambiente Python no HPC\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# (Ex: carregar módulos, ativar conda)\u001b[39;49;00m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjob_extra_directives\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodule load python/3.10\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msource /seu/path/to/venv/bin/activate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repository/Attention/Sampa-USP/Quantum-Neural-States/.venv/lib/python3.14/site-packages/dask_jobqueue/core.py:661\u001b[39m, in \u001b[36mJobQueueCluster.__init__\u001b[39m\u001b[34m(self, n_workers, job_cls, loop, security, shared_temp_directory, silence_logs, name, asynchronous, dashboard_address, host, scheduler_options, scheduler_cls, interface, protocol, config_name, **job_kwargs)\u001b[39m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mprocesses\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._job_kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._job_kwargs[\u001b[33m\"\u001b[39m\u001b[33mprocesses\u001b[39m\u001b[33m\"\u001b[39m] > \u001b[32m1\u001b[39m:\n\u001b[32m    657\u001b[39m     worker[\u001b[33m\"\u001b[39m\u001b[33mgroup\u001b[39m\u001b[33m\"\u001b[39m] = [\n\u001b[32m    658\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m._job_kwargs[\u001b[33m\"\u001b[39m\u001b[33mprocesses\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    659\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dummy_job\u001b[49m  \u001b[38;5;66;03m# trigger property to ensure that the job is valid\u001b[39;00m\n\u001b[32m    663\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    664\u001b[39m     scheduler=scheduler,\n\u001b[32m    665\u001b[39m     worker=worker,\n\u001b[32m   (...)\u001b[39m\u001b[32m    670\u001b[39m     name=name,\n\u001b[32m    671\u001b[39m )\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_workers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repository/Attention/Sampa-USP/Quantum-Neural-States/.venv/lib/python3.14/site-packages/dask_jobqueue/core.py:690\u001b[39m, in \u001b[36mJobQueueCluster._dummy_job\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    688\u001b[39m     address = \u001b[33m\"\u001b[39m\u001b[33mtcp://<insert-scheduler-address-here>:8786\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    689\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjob_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtcp://<insert-scheduler-address-here>:8786\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# The 'name' parameter is replaced inside Job class by the\u001b[39;49;00m\n\u001b[32m    693\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# actual Dask worker name. Using 'dummy-name here' to make it\u001b[39;49;00m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# more clear that cluster.job_script() is similar to but not\u001b[39;49;00m\n\u001b[32m    695\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# exactly the same script as the script submitted for each Dask\u001b[39;49;00m\n\u001b[32m    696\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# worker\u001b[39;49;00m\n\u001b[32m    697\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdummy-name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_job_kwargs\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    701\u001b[39m     \u001b[38;5;66;03m# Very likely this error happened in the self.job_cls constructor\u001b[39;00m\n\u001b[32m    702\u001b[39m     \u001b[38;5;66;03m# because an unexpected parameter was used in the JobQueueCluster\u001b[39;00m\n\u001b[32m    703\u001b[39m     \u001b[38;5;66;03m# constructor. The next few lines builds a more user-friendly error message.\u001b[39;00m\n\u001b[32m    704\u001b[39m     match = re.search(\u001b[33m\"\u001b[39m\u001b[33m(unexpected keyword argument.+)\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(exc))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repository/Attention/Sampa-USP/Quantum-Neural-States/.venv/lib/python3.14/site-packages/dask_jobqueue/slurm.py:37\u001b[39m, in \u001b[36mSLURMJob.__init__\u001b[39m\u001b[34m(self, scheduler, name, queue, project, account, walltime, job_cpu, job_mem, config_name, **base_class_kwargs)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     25\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     26\u001b[39m     scheduler=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     **base_class_kwargs,\n\u001b[32m     36\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbase_class_kwargs\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m queue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     42\u001b[39m         queue = dask.config.get(\u001b[33m\"\u001b[39m\u001b[33mjobqueue.\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.queue\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mself\u001b[39m.config_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repository/Attention/Sampa-USP/Quantum-Neural-States/.venv/lib/python3.14/site-packages/dask_jobqueue/core.py:375\u001b[39m, in \u001b[36mJob.__init__\u001b[39m\u001b[34m(self, scheduler, name, cores, memory, processes, nanny, protocol, security, interface, death_timeout, local_directory, extra, worker_command, worker_extra_args, job_extra, job_extra_directives, env_extra, job_script_prologue, header_skip, job_directives_skip, log_directory, shebang, python, job_name, config_name)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.log_directory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(\u001b[38;5;28mself\u001b[39m.log_directory):\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m         \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlog_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:226\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path.exists(head):\n\u001b[32m    225\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    227\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[32m    228\u001b[39m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[32m    229\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:236\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n\u001b[32m    234\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m    238\u001b[39m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path.isdir(name):\n",
      "\u001b[31mOSError\u001b[39m: [Errno 45] Operation not supported: '/home/nara'"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# PASSO 4: CONFIGURAR O CLUSTER NO HPC\n",
    "# -----------------------------------------------------------------\n",
    "print(\"--- Configurando Conexão com o Cluster HPC ---\")\n",
    "\n",
    "# (Baseado na configuração do seu HPC)\n",
    "cluster = SLURMCluster(\n",
    "    queue='compute',          # Nome da fila/partição do Slurm (ex: 'batch', 'shared')\n",
    "    project='fci-ch4',# O nome do seu projeto/conta para cobrança\n",
    "    cores=24,                 # Quantos cores CADA job (worker) deve pedir\n",
    "    memory='100GB',           # Quanta RAM CADA job (worker) deve pedir\n",
    "    walltime='01:00:00',      # Tempo máximo do job (HH:MM:SS)\n",
    "    \n",
    "    # Configuração de rede (CRUCIAL)\n",
    "    # Tente 'ib0' (InfiniBand) ou 'eth0' (Ethernet)\n",
    "    # Peça ao admin do seu HPC qual interface usar\n",
    "    interface='ib0',\n",
    "    \n",
    "    # Onde salvar os logs dos workers no HPC\n",
    "    log_directory=f'/home/nara/dask-logs',\n",
    "    \n",
    "    # Comandos para carregar seu ambiente Python no HPC\n",
    "    # (Ex: carregar módulos, ativar conda)\n",
    "    job_extra_directives=[\n",
    "        'module load python/3.10',\n",
    "        'source /seu/path/to/venv/bin/activate'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67687e8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "CommClosedError",
     "evalue": "in <TCP (closed)  local=tcp://127.0.0.1:59977 remote=tcp://127.0.0.1:8786>: ConnectionResetError: [Errno 54] Connection reset by peer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionResetError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repository/Attention/Sampa-USP/Quantum-Neural-States/.venv/lib/python3.14/site-packages/tornado/iostream.py:861\u001b[39m, in \u001b[36mBaseIOStream._read_to_buffer\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    860\u001b[39m         buf = \u001b[38;5;28mbytearray\u001b[39m(\u001b[38;5;28mself\u001b[39m.read_chunk_size)\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m     bytes_read = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_from_fd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    863\u001b[39m     \u001b[38;5;66;03m# ssl.SSLError is a subclass of socket.error\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repository/Attention/Sampa-USP/Quantum-Neural-States/.venv/lib/python3.14/site-packages/tornado/iostream.py:1113\u001b[39m, in \u001b[36mIOStream.read_from_fd\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1113\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBlockingIOError\u001b[39;00m:\n",
      "\u001b[31mConnectionResetError\u001b[39m: [Errno 54] Connection reset by peer",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mCommClosedError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m scheduler_address = \u001b[33m'\u001b[39m\u001b[33mtcp://127.0.0.1:8786\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Conectar seu notebook ao agendador do Dask no HPC\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# (Pode ser necessário configurar um Túnel SSH, veja a seção de Segurança)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m client = \u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscheduler_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Pedir ao HPC para iniciar 1 \"job\" (worker)\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# (Isso vai submeter 1 script sbatch)\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSolicitando 1 nó de trabalho do HPC...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repository/Attention/Sampa-USP/Quantum-Neural-States/.venv/lib/python3.14/site-packages/distributed/client.py:1212\u001b[39m, in \u001b[36mClient.__init__\u001b[39m\u001b[34m(self, address, loop, timeout, set_as_default, scheduler_file, security, asynchronous, name, heartbeat_interval, serializers, deserializers, extensions, direct_to_workers, connection_limit, **kwargs)\u001b[39m\n\u001b[32m   1209\u001b[39m preload_argv = dask.config.get(\u001b[33m\"\u001b[39m\u001b[33mdistributed.client.preload-argv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1210\u001b[39m \u001b[38;5;28mself\u001b[39m.preloads = preloading.process_preloads(\u001b[38;5;28mself\u001b[39m, preload, preload_argv)\n\u001b[32m-> \u001b[39m\u001b[32m1212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1213\u001b[39m Client._instances.add(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1215\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrecreate_tasks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReplayTaskClient\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repository/Attention/Sampa-USP/Quantum-Neural-States/.venv/lib/python3.14/site-packages/distributed/client.py:1412\u001b[39m, in \u001b[36mClient.start\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   1410\u001b[39m     \u001b[38;5;28mself\u001b[39m._started = asyncio.ensure_future(\u001b[38;5;28mself\u001b[39m._start(**kwargs))\n\u001b[32m   1411\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1412\u001b[39m     \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repository/Attention/Sampa-USP/Quantum-Neural-States/.venv/lib/python3.14/site-packages/distributed/utils.py:452\u001b[39m, in \u001b[36msync\u001b[39m\u001b[34m(loop, func, callback_timeout, *args, **kwargs)\u001b[39m\n\u001b[32m    449\u001b[39m         wait(\u001b[32m10\u001b[39m)\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repository/Attention/Sampa-USP/Quantum-Neural-States/.venv/lib/python3.14/site-packages/distributed/utils.py:426\u001b[39m, in \u001b[36msync.<locals>.f\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    424\u001b[39m         awaitable = wait_for(awaitable, timeout)\n\u001b[32m    425\u001b[39m     future = asyncio.ensure_future(awaitable)\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     result = \u001b[38;5;28;01myield\u001b[39;00m future\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m    428\u001b[39m     error = exception\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repository/Attention/Sampa-USP/Quantum-Neural-States/.venv/lib/python3.14/site-packages/tornado/gen.py:783\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    782\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m783\u001b[39m         value = \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    784\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    785\u001b[39m         \u001b[38;5;66;03m# Save the exception for later. It's important that\u001b[39;00m\n\u001b[32m    786\u001b[39m         \u001b[38;5;66;03m# gen.throw() not be called inside this try/except block\u001b[39;00m\n\u001b[32m    787\u001b[39m         \u001b[38;5;66;03m# because that makes sys.exc_info behave unexpectedly.\u001b[39;00m\n\u001b[32m    788\u001b[39m         exc: Optional[\u001b[38;5;167;01mException\u001b[39;00m] = e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repository/Attention/Sampa-USP/Quantum-Neural-States/.venv/lib/python3.14/site-packages/distributed/client.py:1490\u001b[39m, in \u001b[36mClient._start\u001b[39m\u001b[34m(self, timeout, **kwargs)\u001b[39m\n\u001b[32m   1487\u001b[39m \u001b[38;5;28mself\u001b[39m.scheduler_comm = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1489\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1490\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ensure_connected(timeout=timeout)\n\u001b[32m   1491\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n\u001b[32m   1492\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repository/Attention/Sampa-USP/Quantum-Neural-States/.venv/lib/python3.14/site-packages/distributed/client.py:1558\u001b[39m, in \u001b[36mClient._ensure_connected\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1555\u001b[39m \u001b[38;5;28mself\u001b[39m._connecting_to_scheduler = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1557\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1558\u001b[39m     comm = \u001b[38;5;28;01mawait\u001b[39;00m connect(\n\u001b[32m   1559\u001b[39m         \u001b[38;5;28mself\u001b[39m.scheduler.address, timeout=timeout, **\u001b[38;5;28mself\u001b[39m.connection_args\n\u001b[32m   1560\u001b[39m     )\n\u001b[32m   1561\u001b[39m     comm.name = \u001b[33m\"\u001b[39m\u001b[33mClient->Scheduler\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1562\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repository/Attention/Sampa-USP/Quantum-Neural-States/.venv/lib/python3.14/site-packages/distributed/comm/core.py:377\u001b[39m, in \u001b[36mconnect\u001b[39m\u001b[34m(addr, timeout, deserialize, handshake_overrides, **connection_args)\u001b[39m\n\u001b[32m    372\u001b[39m local_info = {\n\u001b[32m    373\u001b[39m     **comm.handshake_info(),\n\u001b[32m    374\u001b[39m     **(handshake_overrides \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[32m    375\u001b[39m }\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m comm.write(local_info)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m handshake = \u001b[38;5;28;01mawait\u001b[39;00m comm.read()\n\u001b[32m    379\u001b[39m comm.remote_info = handshake\n\u001b[32m    380\u001b[39m comm.remote_info[\u001b[33m\"\u001b[39m\u001b[33maddress\u001b[39m\u001b[33m\"\u001b[39m] = comm._peer_addr\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repository/Attention/Sampa-USP/Quantum-Neural-States/.venv/lib/python3.14/site-packages/distributed/comm/tcp.py:237\u001b[39m, in \u001b[36mTCP.read\u001b[39m\u001b[34m(self, deserializers)\u001b[39m\n\u001b[32m    235\u001b[39m     \u001b[38;5;28mself\u001b[39m.stream = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    236\u001b[39m     \u001b[38;5;28mself\u001b[39m._closed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     \u001b[43mconvert_stream_closed_error\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# Some OSError, CancelledError or another \"low-level\" exception.\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# We do not really know what was already read from the underlying\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# socket, so it is not even safe to retry here using the same stream.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m# The only safe thing to do is to abort.\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# (See also GitHub #4133, #6548).\u001b[39;00m\n\u001b[32m    244\u001b[39m     \u001b[38;5;28mself\u001b[39m.abort()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repository/Attention/Sampa-USP/Quantum-Neural-States/.venv/lib/python3.14/site-packages/distributed/comm/tcp.py:143\u001b[39m, in \u001b[36mconvert_stream_closed_error\u001b[39m\u001b[34m(obj, exc)\u001b[39m\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc.reason \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mUNKNOWN_CA\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m exc.reason:\n\u001b[32m    142\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m FatalCommClosedError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33min \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m CommClosedError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33min \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mCommClosedError\u001b[39m: in <TCP (closed)  local=tcp://127.0.0.1:59977 remote=tcp://127.0.0.1:8786>: ConnectionResetError: [Errno 54] Connection reset by peer"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------------------------\n",
    "# PASSO 5: CONECTAR E SUBMETER O CÁLCULO PESADO\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "scheduler_address = 'tcp://127.0.0.1:8786'\n",
    "\n",
    "# Conectar seu notebook ao agendador do Dask no HPC\n",
    "# (Pode ser necessário configurar um Túnel SSH, veja a seção de Segurança)\n",
    "client = Client(scheduler_address)\n",
    "\n",
    "# Pedir ao HPC para iniciar 1 \"job\" (worker)\n",
    "# (Isso vai submeter 1 script sbatch)\n",
    "print(\"Solicitando 1 nó de trabalho do HPC...\")\n",
    "cluster.scale(jobs=1) \n",
    "\n",
    "print(f\"Cluster iniciado! Dashboard: {client.dashboard_link}\")\n",
    "print(\"Aguardando o job ser alocado pelo Slurm... (Isso pode levar minutos)\")\n",
    "\n",
    "# Espera até que o worker esteja pronto\n",
    "client.wait_for_workers(1) \n",
    "\n",
    "print(\"\\n--- Iniciando Cálculo REMOTO (N2) no HPC ---\")\n",
    "start_remote = time.time()\n",
    "\n",
    "# 1. Submeter o cálculo pesado. Isso retorna um \"Future\" (uma promessa)\n",
    "future_n2 = client.submit(run_pyscf_fci, n2_atom, n2_basis, n2_spin)\n",
    "\n",
    "# 2. Pegar o resultado.\n",
    "# O .result() é bloqueante: seu notebook vai esperar aqui\n",
    "# até que o HPC termine o cálculo e envie o resultado.\n",
    "e_remote_n2 = future_n2.result() \n",
    "\n",
    "end_remote = time.time()\n",
    "print(f\"Energia Remota N2 (FCI/{n2_basis}): {e_remote_n2:.8f} Ha\")\n",
    "print(f\"Tempo remoto (incluindo espera): {end_remote - start_remote:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c15b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# PASSO 6: DESLIGAR\n",
    "# -----------------------------------------------------------------\n",
    "print(\"\\n--- Desligando ---\")\n",
    "client.close()\n",
    "cluster.close()\n",
    "print(\"Cálculos concluídos. Cluster desligado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc68f5d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mpi4pyscf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7083/3755140918.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmpi4pyscf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscf\u001b[0m    \u001b[0;31m# substitui pyscf.scf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmpi4pyscf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdf\u001b[0m     \u001b[0;31m# (opcional) p/ density-fitting paralela\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyscf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"H 0 0 0; H 0 0 0.74\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cc-pVTZ\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Bohr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mpi4pyscf'"
     ]
    }
   ],
   "source": [
    "from mpi4pyscf import scf    # substitui pyscf.scf\n",
    "from mpi4pyscf import df     # (opcional) p/ density-fitting paralela\n",
    "from pyscf import gto\n",
    "\n",
    "mol = gto.M(atom=\"H 0 0 0; H 0 0 0.74\", basis=\"cc-pVTZ\", unit=\"Bohr\")\n",
    "\n",
    "# SCF paralelo (cada rank faz parte do trabalho)\n",
    "mf = scf.RHF(mol)\n",
    "mf.max_memory = 48_000\n",
    "E = mf.kernel()\n",
    "if mf.mpi_rank == 0:\n",
    "    print(\"E(SCF) =\", E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f6bff",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSH sisko Python3 (HPC)",
   "language": "",
   "name": "rik_ssh_sisko_python3hpc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
